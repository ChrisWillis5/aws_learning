1. Run a spark job to load data into a s3
2. Build and Run a crawler to create table.
3. Run a spark job to load data into a s3 to a load_date folder
4. Build and Run a crawler to create table.  Check the partition.
5. Run the spark job to add another folder.load_date folder
6. Run crawler again to see the new metadata.
7. Add a new col in the datasets by changing the spark code.
8. Run crawler again to see the new metadata.

http://127.0.0.1:7080/?token=b7cf5ec2b40528e783604e39a41e6d6d86a1addba9c26567

